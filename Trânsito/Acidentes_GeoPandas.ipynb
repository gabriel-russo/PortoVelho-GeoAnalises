{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from json import load\n",
    "from requests import Session\n",
    "from os.path import exists\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparação: Requisição dos dados da API do Observatório\n",
    "\n",
    "> Nota: Não é possível solicitar dados de vítima não fatal mais vítima fatal, pois retorna o código `http 500 - Internal Server Error` - Erro no tempo de execução. Será feito duas requisições separadas e inseridas em arquivos diferentes, e então feito a colagem em seguida."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "session = Session()\n",
    "\n",
    "params_nao_fatal = {\"data\":\"[[\\\"Todos\\\"],[\\\"PORTO VELHO\\\"],[\\\"VÍTIMA NÃO FATAL\\\"],[\\\"Todos\\\"],[\\\"1/2019\\\"],[\\\"12/2020\\\"]]\",\n",
    "          \"labels\": \"[\\\"Natureza_do_Acidente\\\",\\\"Municipio\\\",\\\"Consequencia\\\",\\\"Via_1\\\",\\\"Data_Inicial\\\",\\\"Data_Final\\\"]\"}\n",
    "\n",
    "params_fatal = {\"data\":\"[[\\\"Todos\\\"],[\\\"PORTO VELHO\\\"],[\\\"VÍTIMA FATAL\\\"],[\\\"Todos\\\"],[\\\"1/2019\\\"],[\\\"12/2020\\\"]]\",\n",
    "          \"labels\": \"[\\\"Natureza_do_Acidente\\\",\\\"Municipio\\\",\\\"Consequencia\\\",\\\"Via_1\\\",\\\"Data_Inicial\\\",\\\"Data_Final\\\"]\"}\n",
    "\n",
    "cookie = {'chave':'lgpd'}\n",
    "\n",
    "if not exists('AcidentesdeTransitoNaoFatal.json'):\n",
    "    req = Session.post(session, url='http://observatorio.sepog.ro.gov.br/TransitoPerfil/GetGeoData', json=params_nao_fatal, cookies=cookie, stream=True)\n",
    "    with open('AcidentesdeTransitoNaoFatal.json', 'wb') as arq_acidentes:\n",
    "        arq_acidentes.write(req.content)\n",
    "\n",
    "if not exists('AcidentesdeTransitoFatal.json'):\n",
    "    req = Session.post(session, url='http://observatorio.sepog.ro.gov.br/TransitoPerfil/GetGeoData',json=params_fatal,cookies=cookie, stream=True)\n",
    "    with open('AcidentesdeTransitoFatal.json', 'wb') as arq_acidentes:\n",
    "        arq_acidentes.write(req.content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Primeiro passo: Normalização do JSON\n",
    "- Será normalizado usando um método do pandas: [json_normalize](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html)\n",
    "\n",
    "Formato padrão do dado:\n",
    "```\n",
    "{\n",
    "    \"<tipo de acidente>\": {\n",
    "        \"<id>\": {\n",
    "            \"LATITUDE\": <float>,\n",
    "            \"LONGITUDE\": <float>,\n",
    "            \"CONSEQUENCIA\": <string>,\n",
    "            \"MUNICIPIO\": <string>,\n",
    "            \"VEICULO_1\": <string>,\n",
    "            \"VEICULO_2\": <string>,\n",
    "            \"DATA_DO_FATO\": <datetime>,\n",
    "            \"FROTA\": <int>\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('AcidentesdeTransitoNaoFatal.json', 'r') as arq_acidentes:\n",
    "    acidentes = load(arq_acidentes)\n",
    "\n",
    "    df = pd.DataFrame() # Crio um DataFrame vazio onde irá reunir os dados normalizados\n",
    "\n",
    "    for tipo_acidente, acidente in acidentes.items(): # Para cada tipo de acidente ...\n",
    "        for id_, informacoes in acidente.items(): # Para cada item do tipo de acidente...\n",
    "            informacoes.update({'ID':id_})\n",
    "            df_items = pd.json_normalize(informacoes)\n",
    "            df = pd.concat((df, df_items), ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('AcidentesdeTransitoFatal.json', 'r') as arq_acidentes:\n",
    "    acidentes = load(arq_acidentes)\n",
    "\n",
    "    # Mesma lógica para este DF\n",
    "    for tipo_acidente, acidente in acidentes.items():\n",
    "        for id_, informacoes in acidente.items():\n",
    "            informacoes.update({'ID':id_})\n",
    "            df_items = pd.json_normalize(informacoes)\n",
    "            df = pd.concat((df, df_items), ignore_index=True) # Como o DF já existe, utilizo ele para a inserção.\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segundo passo: Limpeza dos dados\n",
    "- Retirar números após a virgula + a virgula do ID\n",
    "- Excluir dados sem LATLON\n",
    "- Tratando dados LATLON para gerar Geometria válida\n",
    "- Substituir valores vazios das colunas VEICULO_1 e VEICULO_2 com `NÃO INFORMADO`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Removendo a virgula mais números após"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se tiver algum id com virgula mais qualquer outra coisa depois\n",
    "if df['ID'].str.contains(r'\\d,.*?').astype(bool).any():\n",
    "    dados_incorretos = df['ID'].loc[df['ID'].str.contains(r'\\d,.*?')]\n",
    "    # Para cada id, selec. da vírgula para frente e apague\n",
    "    dados_corretos = dados_incorretos.apply(lambda id_: sub(r'(?=,).+','', id_))\n",
    "    # Inserir dados corrigidos no DataFrame\n",
    "    df.loc[dados_corretos.index, ['ID']] = dados_corretos.to_frame()['ID']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Remover dados que estão sem geo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(df.loc[(df.LATITUDE == \"SEM GEO\") | (df.LONGITUDE == \"SEM GEO\")].index, inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tratando dados para gerar Geometria válida"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Procurar dados com caracteres especiais"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Previnir que o LATLON tenha qualquer caracter especial OU 2 pontos OU 2 hífen\n",
    "Regex_Sem_Carac_Espec = r'[\\!\\\"\\#\\$%\\&\\'\\(\\)\\*\\+\\,\\/\\:\\;\\<\\=\\>\\?\\@\\[\\]\\^\\_\\`\\{\\|\\}\\~]+|[\\.]{2,}|[\\-]{2,}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. Corrigir esses dados utilizando regex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se tiver caracteres ou duplicações de caract. ...\n",
    "if df['LATITUDE'].str.contains(Regex_Sem_Carac_Espec).astype(bool).any():\n",
    "    # Pegar linhas que estão com problemas\n",
    "    dados_incorretos = df['LATITUDE'].loc[df['LATITUDE'].str.contains(Regex_Sem_Carac_Espec)]\n",
    "    # Consertar erros\n",
    "    dados_corretos = dados_incorretos.apply(lambda lat: sub(r'[^\\-\\d\\.]|(\\.)(?=\\.)|(\\-)(?=\\-)','', lat))\n",
    "    # Inserir dados corrigidos no DataFrame\n",
    "    df.loc[dados_corretos.index, ['LATITUDE']] = dados_corretos.to_frame()['LATITUDE']\n",
    "\n",
    "if df['LONGITUDE'].str.contains(Regex_Sem_Carac_Espec).astype(bool).any():\n",
    "    dados_incorretos = df['LONGITUDE'].loc[df['LONGITUDE'].str.contains(Regex_Sem_Carac_Espec)]\n",
    "    dados_corretos = dados_incorretos.apply(lambda lat: sub(r'[^\\-\\d\\.]|(\\.)(?=\\.)|(\\-)(?=\\-)','', lat))\n",
    "    df.loc[dados_corretos.index, ['LONGITUDE']] = dados_corretos.to_frame()['LONGITUDE']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Substituir dados vazios com `NÃO INFORMADO`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Será utilizado o NÃO INFORMADO pois já existe no dado original, irei manter o padrão\n",
    "\n",
    "# Selecione as tuplas da coluna VEICULO_1 que tenham a condição verdadeira e substitua com 'NÃO INFOMADO'\n",
    "df.loc[df.VEICULO_1 == '', 'VEICULO_1'] = 'NÃO INFORMADO'\n",
    "df.loc[df.VEICULO_2 == '', 'VEICULO_2'] = 'NÃO INFORMADO'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Terceiro Passo: Converção de dados e criar GeoDataFrame\n",
    "- Mudar tipo de dado da coluna DATA_DO_FATO para `datetime`\n",
    "- Mudar tipo de dado das colunas LATITUDE E LONGITUDE para `float`\n",
    "- Mudar tipo de dado da coluna ID para `int`\n",
    "- Gerar um `GeoDataFrame` válido a partir do `DataFrame`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convertendo coluna DATA_DO_FATO para datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.loc[:,'DATA_DO_FATO'] = pd.to_datetime(df['DATA_DO_FATO'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convertendo colunas LATITUDE e LONGITUDE para float"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.loc[:, 'LATITUDE'] = pd.to_numeric(df['LATITUDE'], downcast='float')\n",
    "df.loc[:, 'LONGITUDE'] = pd.to_numeric(df['LONGITUDE'], downcast='float')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convertendo coluna ID para int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.loc[:,'ID'] = pd.to_numeric(df['ID'], downcast='signed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verificar se as conversões estão corretas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gerar `GeoDataFrame` utilizando o construtor do GeoPandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gerar um GeoDataFrame a partir do DataFrame utilizando as colunas LATLON\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.LONGITUDE, df.LATITUDE), crs='EPSG:4674')\n",
    "# Não é mais necessários as colunas...\n",
    "gdf.drop(['LATITUDE', 'LONGITUDE'], axis=1, inplace=True)\n",
    "\n",
    "gdf.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}